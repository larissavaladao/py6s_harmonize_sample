{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Earth Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=bKh-zhe0BsfBMcDDj8Ez-2MRf-mryLmFPO4gEzKGhxY&tc=yOjcQCeelloERk0I97kjWDawCeAG9CjbxcBc-Ry6s8E&cc=MSKNDxFi0lK2UTr6G_-5Yx6IJTA4-FtP8NQfST0kbmA>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=bKh-zhe0BsfBMcDDj8Ez-2MRf-mryLmFPO4gEzKGhxY&tc=yOjcQCeelloERk0I97kjWDawCeAG9CjbxcBc-Ry6s8E&cc=MSKNDxFi0lK2UTr6G_-5Yx6IJTA4-FtP8NQfST0kbmA</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project='ee-curuai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CHLOROPHYLL', 'CHLOROPHYLL_A', 'CHLOROPHYLL_B', 'CLOUD_COVER',\n",
       "       'DEPTH_CLASS', 'DOC', 'ID', 'LATITUDE', 'LOCATION', 'LONGITUDE',\n",
       "       'MISSION', 'N_TOTAL', 'N_TOTAL_DISSOLVED', 'POC', 'P_ORGANIC',\n",
       "       'P_TOTAL', 'SAMPLE_SITE', 'SAMPLING_DEPTH', 'SILICA', 'SPM', 'TOC',\n",
       "       'TOTAL_DEPTH', 'TURBIDITY', 'WATER_PERIOD', 'blue_max', 'blue_mean',\n",
       "       'blue_median', 'blue_min', 'blue_stdDev', 'count_pixel', 'datetime',\n",
       "       'dif_date_point', 'green_max', 'green_mean', 'green_median',\n",
       "       'green_min', 'green_stdDev', 'img_date', 'nir_max', 'nir_mean',\n",
       "       'nir_median', 'nir_min', 'nir_stdDev', 'red_max', 'red_mean',\n",
       "       'red_median', 'red_min', 'red_stdDev', 'system_index',\n",
       "       'dif_date_point_abs', 'satellite'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"C:/Users/LarissaVieiraValadão/Downloads/clean_min_data.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "df = pd.read_csv('C:/Users/l_v_v/Documents/GitHub/py6s_harmonize_sample/datasets/Landsat Sampling/Merged Landsat Data/Drop Outlier Data/clean_min_data.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPM             0\n",
       "blue_mean       0\n",
       "green_mean      0\n",
       "nir_mean        0\n",
       "red_mean        0\n",
       "datetime        0\n",
       "WATER_PERIOD    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_subset = df[['SPM','blue_mean', \n",
    "       'green_mean',\n",
    "       'nir_mean', \n",
    "       'red_mean',\n",
    "       'datetime',\n",
    "       'WATER_PERIOD']].copy()\n",
    "# retirar valores em branco\n",
    "df_subset = df_subset.dropna()\n",
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns_X_model = ['SPM','datetime','WATER_PERIOD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de calculo de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(y_true,y_pred):\n",
    "    ''' y = observed target values\n",
    "    y_pred = predicted target values'''\n",
    "    from sklearn.metrics import r2_score\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_absolute_percentage_error\n",
    "    from sklearn.metrics import explained_variance_score\n",
    "\n",
    "    return {'r2':r2_score(y_true, y_pred),\n",
    "'mae':mean_absolute_error(y_true, y_pred),\n",
    "'mse':mean_squared_error(y_true, y_pred),\n",
    "'mape':mean_absolute_percentage_error(y_true, y_pred),\n",
    "'exp_var': explained_variance_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model_metrics(model,X,y,n_cv=5):\n",
    "    ''' model = model to evaluate\n",
    "    X = predictors\n",
    "    y = observed target values\n",
    "    cv = number of cross validations, standard is 5'''\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=n_cv, test_size=0.15, random_state=0)\n",
    "    from sklearn.model_selection import cross_val_score   \n",
    "       \n",
    "    return {'r2':abs(cross_val_score(model, X, y, cv=cv,scoring='r2')).mean(),\n",
    "'mae':abs(cross_val_score(model, X, y, cv=cv,scoring='neg_mean_absolute_error')).mean(),\n",
    "'mse':abs(cross_val_score(model, X, y, cv=cv,scoring='neg_mean_squared_error')).mean(),\n",
    "'mape':abs(cross_val_score(model, X, y, cv=cv,scoring='neg_mean_absolute_percentage_error')).mean(),\n",
    "'exp_var': abs(cross_val_score(model, X, y, cv=cv,scoring='explained_variance')).mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate parameters\n",
    "y = df_subset['SPM'].copy()\n",
    "X = df_subset.drop(drop_columns_X_model,axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the training into 3481 training and 1519 validation samples\n",
    "sample = sample.randomColumn(seed = 1)\n",
    "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
    "validation = sample.filter(ee.Filter.gte('random', 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest with hyperparameter tuning ...\n",
    "num_trees = ee.List.sequence(5, 200, 5)\n",
    "\n",
    "def train(num_trees):\n",
    "  \"\"\"Train a Random Forest with N trees\"\"\"\n",
    "  classifier = ee.Classifier.smileRandomForest(num_trees).train(features=training,\n",
    "      classProperty = 'cropland', inputProperties = composite.bandNames())\n",
    "  return classifier;\n",
    "\n",
    "\n",
    "def train_acc(num_trees):\n",
    "  acc = ee.Classifier.smileRandomForest(num_trees).train(\n",
    "        features=training,\n",
    "        classProperty='cropland',\n",
    "        inputProperties=composite.bandNames()\n",
    "      ).confusionMatrix().accuracy()\n",
    "  return acc\n",
    "\n",
    "\n",
    "\n",
    "classifiers = num_trees.map(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the classifier that returns the highest accuracy on the validation set.\n",
    "def get_accuracy(classifier):\n",
    "  return validation.classify(classifier).errorMatrix('cropland', 'classification').accuracy()\n",
    "\n",
    "accuracies = classifiers.map(get_accuracy)\n",
    "display(accuracies)\n",
    "\n",
    "# Pick the most accurate classifier\n",
    "i = ee.Array(accuracies).argmax().get(0)\n",
    "classifier = classifiers.get(i)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
